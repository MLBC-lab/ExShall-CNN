{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e1ca20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this notebook, we try to implement a Shallow CNN\n",
    "# in PyTorch for \"Retina Blood Vessel\" dataset\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39f64d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "#\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import skimage\n",
    "from skimage import segmentation, io, filters, morphology\n",
    "import sklearn\n",
    "from sklearn import ensemble, metrics, svm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch, torchvision\n",
    "\n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f18c6227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Globals\n",
    "#\n",
    "train_image_ipath = 'RetinaBloodVessels/train/image/'\n",
    "train_mask_ipath = 'RetinaBloodVessels/train/mask/'\n",
    "test_image_ipath = 'RetinaBloodVessels/test/image/'\n",
    "test_mask_ipath = 'RetinaBloodVessels/test/mask/'\n",
    "NROWS, NCOLS = 512, 512\n",
    "EPSILON = 1e-6\n",
    "br = set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "081c80e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# functions and classes\n",
    "\n",
    "def read_images(path, rescale=True):\n",
    "    images_fnames = sorted(glob.glob(os.path.join(path, '*.png')))\n",
    "    images = []\n",
    "    for fn in images_fnames:\n",
    "        img = io.imread(fn)\n",
    "        if rescale:\n",
    "            img = np.float64(img)\n",
    "            # img = (img - img.min()) / (img.max() + EPSILON)\n",
    "            # img = 2*img - 1\n",
    "            # img = np.float64(img)/img.max()\n",
    "            img = (img - img.mean()) / img.std()\n",
    "        images.append(img)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "def gray(img):\n",
    "    gr = img.mean(axis=2)\n",
    "    gr = (gr - gr.min()) / (gr.max() - gr.min() + EPSILON)\n",
    "    return gr\n",
    "\n",
    "def show(img):\n",
    "    if img.max != 255:\n",
    "        img = np.float64(img)\n",
    "        img = np.uint8(255*(img - img.min())/(img.max()-img.min() + EPSILON))\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    ax = fig.subplots()\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    return True\n",
    "\n",
    "class Activ(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.a = torch.nn.Parameter(torch.randn(1))\n",
    "    def forward(self, x):\n",
    "        return torch.sin(self.a*torch.pi*x)\n",
    "\n",
    "# ShallowCNN Block\n",
    "class ShallowCNN(torch.nn.Module):\n",
    "    def __init__(self, ksize=[(1, 1)], och=[1]):\n",
    "        super().__init__()\n",
    "        self.ksize = ksize\n",
    "        self.conv = torch.nn.ModuleList()\n",
    "        chc = 0\n",
    "        for ks, oc in zip(ksize, och):\n",
    "            self.conv.append(torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(in_channels=3, out_channels=oc,\n",
    "                                kernel_size=ks, stride=1, \n",
    "                                padding='same', bias=True),\n",
    "                # torch.nn.LogSigmoid()))\n",
    "                # torch.nn.Identity()))\n",
    "                torch.nn.ReLU()))\n",
    "                # torch.nn.Tanh()))\n",
    "                # Activ()))\n",
    "            chc += oc\n",
    "        self.aggregate = torch.nn.Conv2d(in_channels=chc, out_channels=1,\n",
    "                                         kernel_size=1, stride=1,\n",
    "                                         padding='same', bias=True)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "        # weight = torch.ones_like(self.conv.weight)\n",
    "        # weight /= weight.sum()\n",
    "        # self.conv.weight = torch.nn.parameter.Parameter(weight,\n",
    "        #                                                 requires_grad=False)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        # print(batch.shape)\n",
    "        out = []\n",
    "        for layer in self.conv:\n",
    "            out.append(layer(batch))\n",
    "            # print(out[-1].shape)\n",
    "        out = torch.concatenate(out, axis=1)\n",
    "        out = self.aggregate(out)\n",
    "        out = self.sigmoid(out)\n",
    "        # print(out.shape)\n",
    "        return out\n",
    "\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        # #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return 1 - dice\n",
    "\n",
    "# Dice Binary Cross Entropy Coefficient\n",
    "class DiceBCELoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "\n",
    "        # #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        # inputs = torch.sigmoid(inputs)\n",
    "\n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)\n",
    "        BCE = torch.nn.functional.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE\n",
    "    \n",
    "class Train:\n",
    "    \"\"\"\n",
    "    Initialize, train, evaluate, decode\n",
    "    \"\"\"\n",
    "    def __init__(self, model, data, label, nepoch=4, bsize=8):\n",
    "        \"\"\"\n",
    "        data: [batch, num_channel, rows, cols]\n",
    "        label: [batch, num_channel, rows, cols]\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        self.nepoch = nepoch\n",
    "        self.device = (torch.device(\"mps\")\n",
    "                       if torch.backends.mps.is_available()\n",
    "                       else torch.device('cpu'))\n",
    "        # self.crit = torch.nn.MSELoss()\n",
    "        # self.crit = DiceLoss()\n",
    "        self.crit =DiceBCELoss()\n",
    "        self.bsize = bsize\n",
    "    def run(self, lr=1e-4):\n",
    "        model = self.model\n",
    "        model = model.to(self.device)\n",
    "        crit = self.crit\n",
    "        optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        # sch = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        #     optim, factor=0.5, patience=4, threshold=0.001)\n",
    "        t1 = time.time()\n",
    "        for epoch in range(self.nepoch):\n",
    "            # t1 = time.time()\n",
    "            model, optim = self._train(model, crit, optim)\n",
    "            # model.train()\n",
    "            # for bc in range(1, self.data.shape[0] // self.bsize):\n",
    "            #     slc = slice((bc-1)*self.bsize, bc*self.bsize)\n",
    "            #     batch, lb = self.data[slc], self.label[slc]\n",
    "            #     batch, lb = batch.to(self.device), lb.to(self.device)\n",
    "            #     optim.zero_grad()\n",
    "            #     out = model(batch).squeeze(dim=1)\n",
    "            #     loss = crit(out, lb)\n",
    "            #     loss.backward()\n",
    "            #     optim.step()\n",
    "            \n",
    "            loss = self._valid(model, crit)\n",
    "            # sch.step(loss)\n",
    "            # if lr != optim.param_groups[0]['lr']:\n",
    "            #     lr = optim.param_groups[0]['lr']\n",
    "            #     print(f'Learning rate changed to {lr:.04f}.')\n",
    "            if (epoch % 10 == 0) | (epoch == (self.nepoch-1)):\n",
    "                print(f'Ep: {epoch}, Secs: {time.time() - t1:.0f}, ' + \n",
    "                      f'loss: {loss:.04f}')\n",
    "                t1 = time.time()\n",
    "            \n",
    "    def _train(self, model, crit, optim):\n",
    "        model.train()\n",
    "        for bc in range(1, self.data.shape[0] // self.bsize):\n",
    "            slc = slice((bc-1)*self.bsize, bc*self.bsize)\n",
    "            batch, lb = self.data[slc], self.label[slc]\n",
    "            batch, lb = batch.to(self.device), lb.to(self.device)\n",
    "            optim.zero_grad()\n",
    "            out = model(batch).squeeze(dim=1)\n",
    "            loss = crit(out, lb)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "        return model, optim\n",
    "    \n",
    "    def _valid(self, model, crit):\n",
    "        model = model.to(self.device)\n",
    "        model.eval()\n",
    "        loss_sum = 0.0\n",
    "        with torch.no_grad():\n",
    "            for bc in range(1, self.data.shape[0] // self.bsize):\n",
    "                slc = slice((bc-1)*self.bsize, bc*self.bsize)\n",
    "                batch, lb = self.data[slc], self.label[slc]\n",
    "                batch, lb = batch.to(self.device), lb.to(self.device)\n",
    "                out = model(batch).squeeze(dim=1)\n",
    "                loss = crit(out, lb)\n",
    "                loss_sum += loss.item()\n",
    "        return loss_sum / bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "a2de1972",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 512, 512, 3) (80, 512, 512) (20, 512, 512, 3) (20, 512, 512)\n",
      "-1.5989004704853944 4.097728417232479 1.5034270125132329e-18\n"
     ]
    }
   ],
   "source": [
    "# read all images and masks and store in two matrices\n",
    "train_images = read_images(train_image_ipath)\n",
    "train_masks = 1 * (read_images(train_mask_ipath, rescale=False) > 0)\n",
    "test_images = read_images(test_image_ipath)\n",
    "test_masks = 1 *(read_images(test_mask_ipath, rescale=False) > 0)\n",
    "print(train_images.shape, train_masks.shape,\n",
    "      test_images.shape, test_masks.shape)\n",
    "print(train_images.min(), train_images.max(), train_images.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "e947db35-7aed-43fe-ba1b-e76696eb4175",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ibat = torch.Tensor(train_images[:2, :, :, :])\n",
    "# ibat = torch.swapdims(ibat, 1, 3)\n",
    "# scnn = ShallowCNN(ksize=[1, 3, 5],\n",
    "#                   och=[20, 20, 20])\n",
    "# print(scnn)\n",
    "# # obat = scnn(ibat)\n",
    "# # for iimg, oimg in zip(ibat, obat):\n",
    "# #     show(torch.swapdims(iimg, 0, 2).detach().numpy())\n",
    "# #     show(torch.swapdims(oimg, 0, 2).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "e371f26f-3677-4cce-a583-cecba36cfb04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep: 0, Secs: 1, loss: 1.1561\n",
      "Ep: 10, Secs: 6, loss: 1.1437\n",
      "Ep: 20, Secs: 6, loss: 1.1416\n",
      "Ep: 30, Secs: 6, loss: 1.1422\n",
      "Ep: 40, Secs: 6, loss: 1.1392\n",
      "Ep: 50, Secs: 6, loss: 1.1386\n",
      "Ep: 60, Secs: 6, loss: 1.1393\n",
      "Ep: 70, Secs: 6, loss: 1.1396\n",
      "Ep: 79, Secs: 6, loss: 1.1379\n",
      "Finished in 52 seconds.\n"
     ]
    }
   ],
   "source": [
    "# scnn = ShallowCNN(ksize=[1, 3, 5, 7, 9, 11],\n",
    "#                   och = [1, 1, 1, 1, 1, 1])\n",
    "# scnn = ShallowCNN(ksize=[(1, 1), (3, 1), (1, 3), (3, 3),],\n",
    "#                          # (1, 5), (5, 1), (3, 5), (5, 3), (5, 5)],\n",
    "#                   och = [1, 1, 1, 1])\n",
    "scnn = ShallowCNN(ksize=[(1, 1), (3, 3), (5, 5), (7, 7)],\n",
    "                  och = [1, 1, 1, 1])\n",
    "train = Train(scnn, torch.Tensor(train_images).swapdims(1, 3),\n",
    "              torch.Tensor(train_masks), nepoch=80, bsize=4)\n",
    "t0 = time.time()\n",
    "train.run(lr=1.0e-2)\n",
    "print(f'Finished in {time.time() - t0:.0f} seconds.')\n",
    "# Records:\n",
    "#    Time: 299, Loss: 1.1772 \n",
    "#    Time: 313, Loss: 1.1651\n",
    "#    Time: 63,  Loss: 1.1791\n",
    "#    Time: 84,  Loss: 1.1367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b19777e-d16e-40cf-961c-b26efa55012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One issue with CNN is that it get the convolution and then the activation\n",
    "# is used. Instead, if we could have a function with all local values as input\n",
    "# then a better nonlinearity could be found.\n",
    "\n",
    "# Using kernel==1 and polynomial activation, we can use AvgPool2d to design\n",
    "# a locally optimized segmentor.\n",
    "# AvgPool2d is a convolution with an all-one window. So, nothing!\n",
    "\n",
    "# We can shift an image into different directions to make an overlapped \n",
    "# neighbors. Then we can define a PyTorch multi-input nonlinear function and\n",
    "# then try to optimize its parameters to estimate the best function for \n",
    "# the segmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
